// src/shared/api/ai/emotionFaceProcessor.ts

import * as tf from "@tensorflow/tfjs";
import { EmotionResult, AiSystemConfig } from "@/shared/types/ai.types";

// Dynamic import types
type FaceMeshModule = typeof import("@mediapipe/face_mesh");
type FaceMeshInstance = import("@mediapipe/face_mesh").FaceMesh;
type Results = import("@mediapipe/face_mesh").Results;

// MediaPipe Face Meshì˜ Resultsì—ì„œ ëœë“œë§ˆí¬ íƒ€ì… ì¶”ì¶œ
type FaceMeshLandmark = Results["multiFaceLandmarks"][number][number];

// Face Mesh ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (app.pyì˜ IDX_FMê³¼ ì •í™•íˆ ì¼ì¹˜)
const IDX_FM = {
  upper_eye: 159,
  lower_eye: 145,
  eye_left: 33,
  eye_right: 133,
  upper_lip: 13,
  lower_lip: 14,
  mouth_left: 61,
  mouth_right: 291,
  mouth_center: 0,
  brow: 65,
  eye_center: 168,
  nose: 1,
  chin: 152,
  cheek_l: 205,
  cheek_r: 425,
};

// í‘œì • ë¼ë²¨ ë° ì¸ë±ìŠ¤ (app.pyì™€ ì •í™•íˆ ì¼ì¹˜)
const LABELS_FACE = ["laugh", "serious", "surprise", "yawn", "none"];
const IDX_FACE = {
  laugh: 0,
  serious: 1, 
  surprise: 2,
  yawn: 3,
  none: 4
};

// app.pyì˜ ë©”íƒ€ë°ì´í„° ì„ê³„ê°’ë“¤ (ì •í™•íˆ ì¼ì¹˜)
const MOUTH_H_Q25 = 0.015;
const EYE_OPEN_Q25 = 0.012;
const BROW_LIFT_Q25 = 0.015;
const SMIRK_T = 0.010;
const FROWN_T = 0.018;
const PUFF_T = 0.015;

// ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ì´ë²¤íŠ¸ ì „ì†¡ ì„ê³„ê°’ (app.pyì˜ SHOW_THRESH ì°¸ê³ )
const EMOTION_THRESHOLDS = {
  laugh: 0.75,     // app.py: 0.90ì—ì„œ ë‚®ì¶¤ (ë” ë¯¼ê°í•˜ê²Œ)
  serious: 0.65,   // app.py: 0.60ì—ì„œ ì•½ê°„ ìƒí–¥
  surprise: 0.80,  // app.py: 0.90ì—ì„œ ë‚®ì¶¤
  yawn: 0.85,      // app.py: 0.90ì—ì„œ ë‚®ì¶¤ (í•˜í’ˆ í¸í–¥ ë°©ì§€)
  none: 0.50       // noneì€ ë‚®ì€ ì„ê³„ê°’
};

// ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ì—°ì† ê°ì§€ ë°©ì§€ë¥¼ ìœ„í•œ ì¿¨ë‹¤ìš´ (ì´ˆ)
const EMOTION_COOLDOWN = {
  laugh: 3.0,
  serious: 5.0,
  surprise: 2.0,
  yawn: 4.0,
  none: 1.0
};

export class EmotionFaceProcessor {
  private faceMesh: FaceMeshInstance | null = null;
  private faceMeshModule: FaceMeshModule | null = null;
  private expressionModel: tf.LayersModel | null = null;
  private expressionScalerMean: number[] | null = null;
  private expressionScalerScale: number[] | null = null;
  private lastExpressionProbs: number[] | null = null; // for smoothing
  private readonly PROBA_ALPHA = 0.3; // app.pyì™€ ë™ì¼

  // MediaPipe onResults ì½œë°±ì—ì„œ ê²°ê³¼ë¥¼ Promiseë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
  private _faceMeshResultResolver: ((value: Results) => void) | null = null;

  // ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ë””ë²„ê¹… ë° ì´ë²¤íŠ¸ ì œì–´
  private lastEmotionEventTime: Record<string, number> = {};
  private debugMode = false;
  private emotionHistory: Array<{emotion: string, confidence: number, timestamp: number}> = [];

  // ì´ˆê¸°í™” ì‹œ AI ì„¤ì • ì£¼ì…
  private aiConfig: AiSystemConfig;

  constructor(initialConfig: AiSystemConfig) {
    this.aiConfig = initialConfig;
    // ê°œë°œ í™˜ê²½ì—ì„œ ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”
    this.debugMode = process.env.NODE_ENV === 'development';
  }

  /**
   * EmotionFaceProcessorë¥¼ ì´ˆê¸°í™”í•˜ê³  ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
   */
  public async init(modelPath: string, scalerPath: string, wasmPath: string): Promise<void> {
    // Client-side check
    if (typeof window === 'undefined') {
      console.warn("EmotionFaceProcessor: Cannot initialize on server side");
      this.aiConfig.emotion.enabled = false;
      return;
    }

    try {
      // Dynamic import of MediaPipe Face Mesh
      this.faceMeshModule = await import("@mediapipe/face_mesh");
      
      // Face Mesh ì´ˆê¸°í™” (app.pyì™€ ë™ì¼í•œ ì„¤ì •)
      this.faceMesh = new this.faceMeshModule.FaceMesh({
        locateFile: (file) => {
          return `${wasmPath}/${file}`;
        },
      });

      this.faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: false, // app.pyì™€ ë™ì¼
        minDetectionConfidence: 0.7, // app.pyì™€ ë™ì¼
        minTrackingConfidence: 0.7,
      });

      this.faceMesh.onResults((results) => {
        if (this._faceMeshResultResolver) {
          this._faceMeshResultResolver(results);
          this._faceMeshResultResolver = null;
        }
      });
      console.log("EmotionFaceProcessor: Face Mesh initialized.");

      // TensorFlow.js ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
      this.expressionModel = await tf.loadLayersModel(modelPath);
      const scalerResponse = await fetch(scalerPath);
      const scalerData = await scalerResponse.json();
      this.expressionScalerMean = scalerData.mean_;
      this.expressionScalerScale = scalerData.scale_;
      console.log("EmotionFaceProcessor: Expression model and scaler loaded.");
      
      // ğŸ”¥ ë””ë²„ê·¸: ìŠ¤ì¼€ì¼ëŸ¬ ë°ì´í„° í™•ì¸
      if (this.debugMode) {
        console.log("Scaler mean length:", this.expressionScalerMean?.length);
        console.log("Scaler scale length:", this.expressionScalerScale?.length);
        console.log("First few mean values:", this.expressionScalerMean?.slice(0, 5));
        console.log("First few scale values:", this.expressionScalerScale?.slice(0, 5));
      }
    } catch (error) {
      console.error("EmotionFaceProcessor: Failed to load Face Mesh or models:", error);
      this.aiConfig.emotion.enabled = false;
      this.faceMesh = null;
      this.faceMeshModule = null;
    }
  }

  /**
   * AI ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
   */
  public updateConfig(config: Partial<AiSystemConfig>): void {
    this.aiConfig = {
      ...this.aiConfig,
      ...config,
      emotion: { ...this.aiConfig.emotion, ...config.emotion },
    };
  }

  /**
   * ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
   */
  public setDebugMode(enabled: boolean): void {
    this.debugMode = enabled;
    console.log(`EmotionFaceProcessor debug mode: ${enabled ? 'ON' : 'OFF'}`);
  }

  /**
   * ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ê°ì • íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ë””ë²„ê¹…ìš©)
   */
  public getEmotionHistory(): Array<{emotion: string, confidence: number, timestamp: number}> {
    return this.emotionHistory.slice(-50); // ìµœê·¼ 50ê°œë§Œ ë°˜í™˜
  }

  /**
   * ì…ë ¥ í”„ë ˆì„ì—ì„œ ì–¼êµ´ í‘œì •ì„ ê°ì§€í•©ë‹ˆë‹¤.
   */
  public async detectEmotion(
    inputImageData: ImageData,
    timestamp: number
  ): Promise<EmotionResult | null> {
    // Client-side check
    if (typeof window === 'undefined') {
      return null;
    }

    if (
      !this.aiConfig.emotion.enabled ||
      !this.faceMesh ||
      !this.expressionModel ||
      !this.expressionScalerMean ||
      !this.expressionScalerScale
    ) {
      return null;
    }

    const canvas = document.createElement("canvas");
    canvas.width = inputImageData.width;
    canvas.height = inputImageData.height;
    const ctx = canvas.getContext("2d");
    if (!ctx) return null;
    ctx.putImageData(inputImageData, 0, 0);

    // MediaPipe ê²°ê³¼ë¥¼ Promiseë¡œ ê¸°ë‹¤ë¦¼
    const resultsPromise = new Promise<Results>((resolve) => {
      this._faceMeshResultResolver = resolve;
    });

    await this.faceMesh.send({ image: canvas });
    const results = await resultsPromise;

    if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
      const faceLandmarks = results.multiFaceLandmarks[0];

      // ğŸ”¥ ë””ë²„ê·¸: ëœë“œë§ˆí¬ ê°œìˆ˜ í™•ì¸
      if (this.debugMode && Math.random() < 0.01) { // 1% í™•ë¥ ë¡œ ë¡œê·¸
        console.log('Face landmarks count:', faceLandmarks.length);
        console.log('Sample landmarks:', {
          upper_eye: faceLandmarks[IDX_FM.upper_eye],
          lower_eye: faceLandmarks[IDX_FM.lower_eye],
          mouth_left: faceLandmarks[IDX_FM.mouth_left],
          mouth_right: faceLandmarks[IDX_FM.mouth_right]
        });
      }

      // íŠ¹ì§• ì¶”ì¶œ
      const extractedFeatures = this.extractFeatures12(faceLandmarks);
      if (!extractedFeatures) {
        return null;
      }

      // ğŸ”¥ ë””ë²„ê·¸: íŠ¹ì§• ê°’ í™•ì¸
      if (this.debugMode && Math.random() < 0.02) { // 2% í™•ë¥ ë¡œ ë¡œê·¸
        console.log('Raw features:', {
          eyeOpen: extractedFeatures[0],
          mouthH: extractedFeatures[1],
          mouthW: extractedFeatures[2],
          browLift: extractedFeatures[3]
        });
      }

      // ìŠ¤ì¼€ì¼ë§
      const scaledFeatures = this.scaleFeatures(extractedFeatures);
      const inputTensor = tf.tensor2d([scaledFeatures], [1, scaledFeatures.length]);
      const prediction = this.expressionModel.predict(inputTensor) as tf.Tensor;
      const probs = prediction.dataSync() as Float32Array;
      tf.dispose(inputTensor);

      // ìŠ¤ë¬´ë”©
      const smoothedProbs = this.smoothProbs(Array.from(probs));
      
      // í›„ì²˜ë¦¬
      let topIdx = smoothedProbs.indexOf(Math.max(...smoothedProbs));
      topIdx = this.gateSurprise(extractedFeatures, smoothedProbs, topIdx);
      const [finalIdx, finalConf] = this.promoteSerious(extractedFeatures, smoothedProbs, topIdx);
      
      const label = LABELS_FACE[finalIdx];
      const confidence = finalConf;

      // ğŸ”¥ ë””ë²„ê·¸: í™•ë¥  ë¶„í¬ ë¡œê·¸ (ê°€ë”ì”©)
      if (this.debugMode && Math.random() < 0.05) { // 5% í™•ë¥ ë¡œ ë¡œê·¸
        const top3 = smoothedProbs
          .map((prob, idx) => ({ label: LABELS_FACE[idx], prob }))
          .sort((a, b) => b.prob - a.prob)
          .slice(0, 3);
        console.log('Top 3 emotions:', top3);
        console.log('Final result:', { label, confidence: confidence.toFixed(3) });
      }

      // ğŸ”¥ ê°ì • íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ëª¨ë“  ê²°ê³¼ ì €ì¥)
      this.emotionHistory.push({ emotion: label, confidence, timestamp });
      if (this.emotionHistory.length > 100) {
        this.emotionHistory.shift(); // ì˜¤ë˜ëœ ê²ƒ ì œê±°
      }

      // ğŸ”¥ ì„ê³„ê°’ ì²´í¬: ì¼ì • ìˆ˜ì¤€ ì´ìƒì¼ ë•Œë§Œ ì´ë²¤íŠ¸ ì „ì†¡
      const threshold = EMOTION_THRESHOLDS[label as keyof typeof EMOTION_THRESHOLDS] || 0.8;
      const cooldown = EMOTION_COOLDOWN[label as keyof typeof EMOTION_COOLDOWN] || 3.0;
      const now = Date.now() / 1000;
      const lastEventTime = this.lastEmotionEventTime[label] || 0;

      // ì„ê³„ê°’ ë¯¸ë‹¬ì´ê±°ë‚˜ ì¿¨ë‹¤ìš´ ì¤‘ì´ë©´ null ë°˜í™˜ (ì´ë²¤íŠ¸ ì „ì†¡ ì•ˆí•¨)
      if (confidence < threshold || (now - lastEventTime) < cooldown) {
        if (this.debugMode && confidence >= threshold) {
          console.log(`${label} detected but in cooldown (${(now - lastEventTime).toFixed(1)}s / ${cooldown}s)`);
        }
        return null;
      }

      // ğŸ”¥ ì´ë²¤íŠ¸ ì „ì†¡ ì¡°ê±´ ë§Œì¡±: ì¿¨ë‹¤ìš´ ì—…ë°ì´íŠ¸
      this.lastEmotionEventTime[label] = now;
      
      if (this.debugMode) {
        console.log(`ğŸ­ EMOTION EVENT: ${label} (${(confidence * 100).toFixed(1)}%) - threshold: ${(threshold * 100).toFixed(0)}%`);
      }

      return {
        type: "emotion",
        label: label,
        confidence: confidence,
        faceLandmarks: faceLandmarks.map((lm) => [lm.x, lm.y, lm.z]),
        timestamp: timestamp,
      };
    }
    return null;
  }

  /**
   * app.pyì˜ extract_features12ì™€ ì •í™•íˆ ë™ì¼í•œ ë¡œì§
   */
  private extractFeatures12(landmarks: FaceMeshLandmark[]): number[] | null {
    try {
      // app.pyì²˜ëŸ¼ 3D ë°°ì—´ë¡œ ë³€í™˜ (ì •ê·œí™”ëœ ì¢Œí‘œ ì‚¬ìš©)
      const arr = landmarks.map(lm => [lm.x, lm.y, lm.z || 0]);
      
      // app.pyì™€ ë™ì¼í•œ ê±°ë¦¬ ê³„ì‚° (3D euclidean distance)
      const euclideanDist = (p1: number[], p2: number[]): number => {
        const dx = p1[0] - p2[0];
        const dy = p1[1] - p2[1]; 
        const dz = p1[2] - p2[2];
        return Math.sqrt(dx * dx + dy * dy + dz * dz);
      };

      // app.pyì™€ ì •í™•íˆ ë™ì¼í•œ íŠ¹ì§• ì¶”ì¶œ
      const eyeOpen = euclideanDist(arr[IDX_FM.upper_eye], arr[IDX_FM.lower_eye]);
      const mouthH = euclideanDist(arr[IDX_FM.upper_lip], arr[IDX_FM.lower_lip]);
      const mouthW = euclideanDist(arr[IDX_FM.mouth_left], arr[IDX_FM.mouth_right]);
      const browLift = euclideanDist(arr[IDX_FM.brow], arr[IDX_FM.eye_center]);
      const eyeW = euclideanDist(arr[IDX_FM.eye_left], arr[IDX_FM.eye_right]);

      // ë¹„ìœ¨ ê³„ì‚°
      const eyeRatio = eyeOpen > 0 ? eyeW / eyeOpen : 0.0;
      const mouthRatio = mouthH > 0 ? mouthW / mouthH : 0.0;
      const browMouthRatio = mouthH > 0 ? browLift / mouthH : 0.0;

      // ì¶”ê°€ íŠ¹ì§•ë“¤
      const mouthCenterY = arr[IDX_FM.mouth_center][1];
      const leftY = arr[IDX_FM.mouth_left][1];
      const rightY = arr[IDX_FM.mouth_right][1];
      const mouthDroop = (leftY + rightY) / 2.0 - mouthCenterY;
      const mouthAsym = Math.abs(leftY - rightY);

      const cheekAvgZ = (arr[IDX_FM.cheek_l][2] + arr[IDX_FM.cheek_r][2]) / 2.0;
      const noseZ = arr[IDX_FM.nose][2];
      const cheekPuff = noseZ - cheekAvgZ;

      const faceScale = euclideanDist(arr[IDX_FM.nose], arr[IDX_FM.chin]);
      
      // app.pyì™€ ë™ì¼í•œ faceScale ì²´í¬
      if (faceScale === 0) {
        return Array(12).fill(0);
      }

      const dx = arr[IDX_FM.mouth_right][0] - arr[IDX_FM.mouth_left][0];
      const dy = arr[IDX_FM.mouth_right][1] - arr[IDX_FM.mouth_left][1];
      const mouthTilt = Math.atan2(dy, dx) / (Math.PI / 2);
      const eyeMouthCoupling = (eyeOpen / faceScale) / ((mouthH / faceScale) + 1e-6);

      // app.pyì™€ ì •í™•íˆ ë™ì¼í•œ ìˆœì„œì˜ 12ê°œ íŠ¹ì§•
      const feats = [
        eyeOpen / faceScale,      // 0
        mouthH / faceScale,       // 1
        mouthW / faceScale,       // 2
        browLift / faceScale,     // 3
        eyeRatio,                 // 4
        mouthRatio,               // 5
        browMouthRatio,           // 6
        mouthDroop / faceScale,   // 7
        mouthAsym / faceScale,    // 8
        cheekPuff / faceScale,    // 9
        mouthTilt,                // 10
        eyeMouthCoupling,         // 11
      ];

      // app.pyì˜ np.nan_to_numê³¼ ë™ì¼
      return feats.map((f) => (isNaN(f) || !isFinite(f) ? 0 : f));
    } catch (e) {
      console.warn("Error extracting facial features:", e);
      return null;
    }
  }

  /**
   * app.pyì™€ ì •í™•íˆ ë™ì¼í•œ ìŠ¤ì¼€ì¼ë§
   */
  private scaleFeatures(features: number[]): number[] {
    if (!this.expressionScalerMean || !this.expressionScalerScale) {
      console.warn("Scaler data not loaded for scaling.");
      return features;
    }
    
    // app.py: (feat_raw - self.MEAN) / (self.SCALE + 1e-8)
    return features.map(
      (f, i) => (f - this.expressionScalerMean![i]) / (this.expressionScalerScale![i] + 1e-8)
    );
  }

  /**
   * app.pyì™€ ì •í™•íˆ ë™ì¼í•œ ìŠ¤ë¬´ë”©
   */
  private smoothProbs(currentProbs: number[]): number[] {
    if (!this.lastExpressionProbs) {
      this.lastExpressionProbs = [...currentProbs];
    } else {
      // app.py: (1-self.PROBA_ALPHA)*self.proba_smooth + self.PROBA_ALPHA*p
      this.lastExpressionProbs = currentProbs.map(
        (p, i) => (1 - this.PROBA_ALPHA) * this.lastExpressionProbs![i] + this.PROBA_ALPHA * p
      );
    }
    return [...this.lastExpressionProbs];
  }

  /**
   * app.pyì˜ gate_surpriseì™€ ì •í™•íˆ ë™ì¼
   */
  private gateSurprise(rawFeat: number[], probs: number[], topIdx: number): number {
    if (topIdx !== IDX_FACE.surprise) {
      return topIdx;
    }

    // app.pyì™€ ë™ì¼í•œ ì¡°ê±´ ì²´í¬
    if (rawFeat[1] < MOUTH_H_Q25 && rawFeat[0] < EYE_OPEN_Q25 && rawFeat[3] < BROW_LIFT_Q25) {
      // app.py: return int(np.argsort(probs)[-2])  // ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í™•ë¥ 
      const indices = Array.from({length: probs.length}, (_, i) => i);
      indices.sort((a, b) => probs[b] - probs[a]);
      return indices[1]; // ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ì¸ë±ìŠ¤
    }
    return topIdx;
  }

  /**
   * app.pyì˜ promote_seriousì™€ ì •í™•íˆ ë™ì¼
   */
  private promoteSerious(rawFeat: number[], probs: number[], currentIdx: number): [number, number] {
    const seriousP = probs[IDX_FACE.serious];
    
    // app.pyì™€ ë™ì¼í•œ íŠ¹ì§• ì¸ë±ìŠ¤ ë° ì„ê³„ê°’
    const smirk = rawFeat[8] > SMIRK_T;  // mouthAsym > 0.010
    const frown = rawFeat[3] < FROWN_T;  // browLift < 0.018
    const puff = rawFeat[9] > PUFF_T;    // cheekPuff > 0.015

    // app.pyì™€ ë™ì¼í•œ ë¡œì§
    if (seriousP >= 0.60 || ((smirk || frown || puff) && seriousP >= 0.45)) {
      return [IDX_FACE.serious, seriousP];
    }
    return [currentIdx, probs[currentIdx]];
  }

  /**
   * ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ì„ê³„ê°’ ë™ì  ì¡°ì • (í•„ìš”ì‹œ ì‚¬ìš©)
   */
  public updateEmotionThreshold(emotion: string, threshold: number): void {
    if (emotion in EMOTION_THRESHOLDS) {
      (EMOTION_THRESHOLDS as any)[emotion] = Math.max(0.1, Math.min(0.99, threshold));
      console.log(`Updated ${emotion} threshold to ${threshold}`);
    }
  }

  /**
   * ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ì¿¨ë‹¤ìš´ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ìš©)
   */
  public resetCooldowns(): void {
    this.lastEmotionEventTime = {};
    console.log('Emotion cooldowns reset');
  }

  /**
   * ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
   */
  public cleanup(): void {
    if (this.faceMesh) {
      this.faceMesh = null;
    }
    if (this.expressionModel) {
      this.expressionModel.dispose();
      this.expressionModel = null;
    }
    this.faceMeshModule = null;
    this.expressionScalerMean = null;
    this.expressionScalerScale = null;
    this.lastExpressionProbs = null;
    this.lastEmotionEventTime = {};
    this.emotionHistory = [];
  }
}