// src/shared/api/ai/gestureProcessor.ts

import {
  HandLandmarker,
  FilesetResolver,
  GestureRecognizer,
  NormalizedLandmark,
} from "@mediapipe/tasks-vision";
import { GestureResult, AiSystemConfig } from "@/shared/types/ai.types";
import * as tf from "@tensorflow/tfjs";

export class GestureProcessor {
  private handLandmarker: HandLandmarker | null = null;
  private gestureRecognizer: GestureRecognizer | null = null;
  private aiConfig: AiSystemConfig;
  
  // TensorFlow.js ëª¨ë¸ë“¤
  private staticGestureModel: tf.LayersModel | null = null;
  private dynamicGestureModel: tf.LayersModel | null = null;
  
  // ëª¨ë¸ ê²½ë¡œ ìƒìˆ˜
  private readonly STATIC_GESTURE_MODEL_PATH = "/models/static-gesture/model.json";
  private readonly DYNAMIC_GESTURE_MODEL_PATH = "/models/dinamic-gesture/model.json"; // ì‹¤ì œ í´ë”ëª…ì— ë§ì¶° ìˆ˜ì •

  // ì°¸ê³  ì½”ë“œì˜ ì•ˆì •í™” ìƒìˆ˜ë“¤ ì¶”ê°€
  private readonly PX_HIGH = 0.10; // ì›€ì§ì„ ì„ê³„ê°’ (ì•½ê°„ë§Œ ë‚®ì¶¤)
  private readonly STATIC_CONF_T = 0.75; // ì •ì  ì œìŠ¤ì²˜ ì‹ ë¢°ë„ ì„ê³„ê°’
  private readonly STATIC_VOTE_K = 10; // ë‹¤ìˆ˜ê²° íˆ¬í‘œ ìˆ˜ (ë” ë§ì€ íˆ¬í‘œ ìš”êµ¬)
  private readonly STATIC_HOLD_SEC = 2.0; // ì •ì  ì œìŠ¤ì²˜ ìœ ì§€ ì‹œê°„ (2ì´ˆ)
  private readonly STATIC_COOLDOWN = 5.0; // ì •ì  ì œìŠ¤ì²˜ ì¿¨ë‹¤ìš´(ì´ˆ) - 5ì´ˆ
  private readonly SEQ_LEN = 30; // ë™ì  ì œìŠ¤ì²˜ ì‹œí€€ìŠ¤ ê¸¸ì´ (ì›ë˜ëŒ€ë¡œ ë³µì›)
  private readonly DYN_CONF_T = 0.85; // ë™ì  ì œìŠ¤ì²˜ ì‹ ë¢°ë„ ì„ê³„ê°’ (ì•½ê°„ë§Œ ë‚®ì¶¤)
  private readonly MOVE3D_T = 0.05; // 3D ì›€ì§ì„ ì„ê³„ê°’ (ì•½ê°„ë§Œ ë‚®ì¶¤)
  private readonly DYN_COOLDOWN = 5.0; // ë™ì  ì œìŠ¤ì²˜ ì¿¨ë‹¤ìš´(ì´ˆ) - 5ì´ˆ

  // ì†ë³„ ìƒíƒœ ê´€ë¦¬
  private handStates: Map<string, {
    staticVote: string[]; // ì •ì  ì œìŠ¤ì²˜ íˆ¬í‘œ ë²„í¼
    lastStaticLabel: string;
    staticLabelStart: number;
    lastStaticTime: Map<string, number>; // ì •ì  ì œìŠ¤ì²˜ë³„ ë§ˆì§€ë§‰ ê°ì§€ ì‹œê°„
    moveHist2d: number[]; // 2D ì›€ì§ì„ íˆìŠ¤í† ë¦¬
    prevWrist2: [number, number] | null;
    prevWrist3: [number, number, number] | null;
    dynamicSequence: number[][]; // ë™ì  ì œìŠ¤ì²˜ ì‹œí€€ìŠ¤
    lastDynTime: Map<string, number>; // ë™ì  ì œìŠ¤ì²˜ë³„ ë§ˆì§€ë§‰ ê°ì§€ ì‹œê°„
    wristNorm: [number, number] | null;
    indexNorm: [number, number] | null;
  }> = new Map();

  private noHandCount = 0;
  private readonly NOHAND_CLEAR_FR = 10;

  constructor(initialConfig: AiSystemConfig) {
    this.aiConfig = initialConfig;
  }

  /**
   * GestureProcessorë¥¼ ì´ˆê¸°í™”í•˜ê³  MediaPipe ì† ì¸ì‹ ëª¨ë¸ ë° TensorFlow.js ëª¨ë¸ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤.
   * @param wasmPath MediaPipe Tasks Vision WASM ê²½ë¡œ (ì˜ˆ: "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm")
   */
  public async init(wasmPath: string): Promise<void> {
    // Client-side check
    if (typeof window === 'undefined') {
      console.warn("GestureProcessor: Cannot initialize on server side");
      this.aiConfig.gesture.static.enabled = false;
      this.aiConfig.gesture.dynamic.enabled = false;
      return;
    }

    console.log("ğŸ¤– Initializing GestureProcessor models...");

    try {
      const vision = await FilesetResolver.forVisionTasks(wasmPath);

      // MediaPipe ëª¨ë¸ë“¤ê³¼ TensorFlow.js ëª¨ë¸ë“¤ì„ ë³‘ë ¬ë¡œ ë¡œë“œ
      await Promise.all([
        this.initMediaPipeModels(vision),
        this.initTensorFlowModels()
      ]);

      console.log("âœ… GestureProcessor: All models initialized successfully.");
    } catch (error) {
      console.error("âŒ GestureProcessor: Failed to initialize models:", error);
      throw error;
    }
  }

  /**
   * MediaPipe ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
   */
  private async initMediaPipeModels(vision: any): Promise<void> {
    // HandLandmarker ìƒì„±
    try {
      this.handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU", // ê¸°ë³¸ì ìœ¼ë¡œ GPU ì‹œë„
        },
        runningMode: "VIDEO",
        numHands: 2,
        minHandDetectionConfidence: 0.7,
        minHandPresenceConfidence: 0.7,
        minTrackingConfidence: 0.7,
      });
      console.log("GestureProcessor: HandLandmarker created successfully with GPU delegate.");
    } catch (gpuError) {
      console.warn(
        "GestureProcessor: GPU delegate failed for HandLandmarker, trying CPU:",
        gpuError
      );
      this.handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "CPU", // GPU ì‹¤íŒ¨ ì‹œ CPU í´ë°±
        },
        runningMode: "VIDEO",
        numHands: 2,
        minHandDetectionConfidence: 0.7,
        minHandPresenceConfidence: 0.7,
        minTrackingConfidence: 0.7,
      });
      console.log("GestureProcessor: HandLandmarker created successfully with CPU delegate.");
    }

    // GestureRecognizer ìƒì„± (ë™ì  ì œìŠ¤ì²˜ìš©ìœ¼ë¡œ ìœ ì§€)
    try {
      this.gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
          delegate: "GPU", // ê¸°ë³¸ì ìœ¼ë¡œ GPU ì‹œë„
        },
        runningMode: "VIDEO",
        numHands: 2,
        minHandDetectionConfidence: 0.7,
        minHandPresenceConfidence: 0.7,
        minTrackingConfidence: 0.7,
      });
      console.log("GestureProcessor: GestureRecognizer created successfully with GPU delegate.");
    } catch (gpuError) {
      console.warn(
        "GestureProcessor: GPU delegate failed for GestureRecognizer, trying CPU:",
        gpuError
      );
      this.gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
          delegate: "CPU", // GPU ì‹¤íŒ¨ ì‹œ CPU í´ë°±
        },
        runningMode: "VIDEO",
        numHands: 2,
        minHandDetectionConfidence: 0.7,
        minHandPresenceConfidence: 0.7,
        minTrackingConfidence: 0.7,
      });
      console.log("GestureProcessor: GestureRecognizer created successfully with CPU delegate.");
    }
  }

  /**
   * TensorFlow.js ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
   */
  private async initTensorFlowModels(): Promise<void> {
    try {
      // TensorFlow.js ë°±ì—”ë“œ ì„¤ì •
      await tf.ready();
      console.log(`TensorFlow.js backend: ${tf.getBackend()}`);

      // ì •ì  ì œìŠ¤ì²˜ ëª¨ë¸ ë¡œë“œ
      if (this.aiConfig.gesture.static.enabled) {
        try {
          console.log(`Loading static gesture model from: ${this.STATIC_GESTURE_MODEL_PATH}`);
          this.staticGestureModel = await tf.loadLayersModel(this.STATIC_GESTURE_MODEL_PATH);
          console.log("âœ… Static gesture model loaded successfully");
        } catch (error) {
          console.warn("âŒ Failed to load static gesture model:", error);
          this.aiConfig.gesture.static.enabled = false;
        }
      }

      // ë™ì  ì œìŠ¤ì²˜ ëª¨ë¸ ë¡œë“œ
      if (this.aiConfig.gesture.dynamic.enabled) {
        try {
          console.log(`Loading dynamic gesture model from: ${this.DYNAMIC_GESTURE_MODEL_PATH}`);
          this.dynamicGestureModel = await tf.loadLayersModel(this.DYNAMIC_GESTURE_MODEL_PATH);
          console.log("âœ… Dynamic gesture model loaded successfully");
        } catch (error) {
          console.warn("âŒ Failed to load dynamic gesture model:", error);
          this.aiConfig.gesture.dynamic.enabled = false;
        }
      }
    } catch (error) {
      console.error("âŒ TensorFlow.js initialization failed:", error);
      throw error;
    }
  }

  /**
   * AI ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
   * @param config ì—…ë°ì´íŠ¸í•  AI ì„¤ì •
   */
  public updateConfig(config: Partial<AiSystemConfig>): void {
    this.aiConfig = {
      ...this.aiConfig,
      ...config,
      gesture: { ...this.aiConfig.gesture, ...config.gesture },
    };
  }

  /**
   * ì† ëœë“œë§ˆí¬ë¥¼ ì†ëª© ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
   * ì°¸ê³  ì½”ë“œì˜ hand_keypoints_relative í•¨ìˆ˜ í¬íŒ…
   */
  private handKeypointsRelative(landmarks: NormalizedLandmark[]): number[] {
    const wrist = landmarks[0];
    const relative: number[] = [];
    
    for (const lm of landmarks) {
      relative.push(
        lm.x - wrist.x,
        lm.y - wrist.y,
        lm.z - wrist.z
      );
    }
    
    return relative;
  }

  /**
   * ì† ìƒíƒœ ì´ˆê¸°í™”
   */
  private initHandState(handKey: string) {
    this.handStates.set(handKey, {
      staticVote: [],
      lastStaticLabel: "none",
      staticLabelStart: 0,
      lastStaticTime: new Map(),
      moveHist2d: [],
      prevWrist2: null,
      prevWrist3: null,
      dynamicSequence: [],
      lastDynTime: new Map(),
      wristNorm: null,
      indexNorm: null,
    });
  }

  /**
   * ì •ì  ì œìŠ¤ì²˜ ê°ì§€ (TensorFlow.js ëª¨ë¸ ì‚¬ìš©)
   * @param landmarks ì† ëœë“œë§ˆí¬ (21ê°œ í¬ì¸íŠ¸)
   * @returns ì •ì  ì œìŠ¤ì²˜ ê²°ê³¼ ë˜ëŠ” null
   */
  private async detectStaticGesture(landmarks: NormalizedLandmark[]): Promise<{ label: string; confidence: number } | null> {
    if (!this.staticGestureModel || !this.aiConfig.gesture.static.enabled) {
      return null;
    }

    try {
      // ì†ëª© ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
      const relativeKeypoints = this.handKeypointsRelative(landmarks);
      
      // TensorFlow.js ëª¨ë¸ì— ë§ëŠ” í˜•íƒœë¡œ ë°ì´í„° ì¤€ë¹„ (1ì°¨ì› ë°°ì—´ì„ 2ì°¨ì› í…ì„œë¡œ)
      const inputTensor = tf.tensor2d([relativeKeypoints], [1, relativeKeypoints.length]);
      
      // ëª¨ë¸ ì¶”ë¡ 
      const prediction = this.staticGestureModel.predict(inputTensor) as tf.Tensor;
      const predictionData = await prediction.data();
      
      // ë©”ëª¨ë¦¬ ì •ë¦¬
      inputTensor.dispose();
      prediction.dispose();
      
      // ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì°¾ê¸°
      const maxProbability = Math.max(...Array.from(predictionData));
      const predictedClassIndex = Array.from(predictionData).indexOf(maxProbability);
      
      // ì •ì  ì œìŠ¤ì²˜ ë ˆì´ë¸” ë§¤í•‘ (11ê°œ í´ë˜ìŠ¤)
      const staticGestureLabels = [
        "bad", "fist", "good", "gun", "heart", "none", 
        "ok", "open_palm", "promise", "rock", "victory"
      ];
      
      const predictedLabel = staticGestureLabels[predictedClassIndex] || "none";
      
      // ë””ë²„ê¹… ë¡œê·¸ (ë‚˜ì¤‘ì— ì œê±° ê°€ëŠ¥)
      // if (maxProbability > 0.5) {
      //   console.log(`Static gesture detected: ${predictedLabel} (${(maxProbability * 100).toFixed(1)}%)`);
      // }
      
      return {
        label: predictedLabel,
        confidence: maxProbability
      };
    } catch (error) {
      console.error("Static gesture detection error:", error);
      return null;
    }
  }

  /**
   * ë™ì  ì œìŠ¤ì²˜ ê°ì§€ (TensorFlow.js ëª¨ë¸ ì‚¬ìš©)
   * @param sequence ì›€ì§ì„ ì‹œí€€ìŠ¤ (SEQ_LEN x 63 ì°¨ì›)
   * @returns ë™ì  ì œìŠ¤ì²˜ ê²°ê³¼ ë˜ëŠ” null
   */
  private async detectDynamicGesture(sequence: number[][]): Promise<{ label: string; confidence: number } | null> {
    if (!this.dynamicGestureModel || !this.aiConfig.gesture.dynamic.enabled || sequence.length !== this.SEQ_LEN) {
      return null;
    }

    try {
      // ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ 3ì°¨ì› í…ì„œë¡œ ë³€í™˜ [1, SEQ_LEN, 63]
      const sequenceArray = sequence.map(frame => frame); // 2D ë°°ì—´
      const inputTensor = tf.tensor3d([sequenceArray], [1, this.SEQ_LEN, sequenceArray[0].length]);
      
      // ëª¨ë¸ ì¶”ë¡ 
      const prediction = this.dynamicGestureModel.predict(inputTensor) as tf.Tensor;
      const predictionData = await prediction.data();
      
      // ë©”ëª¨ë¦¬ ì •ë¦¬
      inputTensor.dispose();
      prediction.dispose();
      
      // ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì°¾ê¸°
      const maxProbability = Math.max(...Array.from(predictionData));
      const predictedClassIndex = Array.from(predictionData).indexOf(maxProbability);
      
      // ë™ì  ì œìŠ¤ì²˜ ë ˆì´ë¸” ë§¤í•‘ (7ê°œ í´ë˜ìŠ¤)
      const dynamicGestureLabels = [
        "fire", "hi", "hit", "none", "nono", "nyan", "shot"
      ];
      
      const predictedLabel = dynamicGestureLabels[predictedClassIndex] || "none";
      
      // ë””ë²„ê¹… ë¡œê·¸ (ë‚˜ì¤‘ì— ì œê±° ê°€ëŠ¥)
      // if (maxProbability > 0.5) {
      //   console.log(`Dynamic gesture detected: ${predictedLabel} (${(maxProbability * 100).toFixed(1)}%)`);
      // }
      
      return {
        label: predictedLabel,
        confidence: maxProbability
      };
    } catch (error) {
      console.error("Dynamic gesture detection error:", error);
      return null;
    }
  }

  /**
   * ì…ë ¥ ë¹„ë””ì˜¤ ìš”ì†Œì—ì„œ ì† ëœë“œë§ˆí¬ ë° ì œìŠ¤ì²˜ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
   * @param videoElement ë¹„ë””ì˜¤ ìš”ì†Œ (HTMLVideoElement) ë˜ëŠ” Canvas (HTMLCanvasElement)
   * @param timestamp í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ (ms)
   * @returns ê°ì§€ëœ ì œìŠ¤ì²˜ ê²°ê³¼ (GestureResult) ë˜ëŠ” null
   */
  public async detectGestures(
    videoElement: HTMLVideoElement | HTMLCanvasElement,
    timestamp: number
  ): Promise<GestureResult | null> {
    // Client-side check
    if (typeof window === 'undefined') {
      return null;
    }

    // Check if we have the required components for the enabled features
    const needsHandLandmarker = this.aiConfig.gesture.static.enabled || this.aiConfig.gesture.dynamic.enabled;
    
    if (needsHandLandmarker && !this.handLandmarker) {
      return null;
    }

    // ì œìŠ¤ì²˜ ì¸ì‹ ì²˜ë¦¬
    if (this.aiConfig.gesture.static.enabled || this.aiConfig.gesture.dynamic.enabled) {
      try {
        const handResults = this.handLandmarker!.detectForVideo(videoElement, timestamp);

        if (handResults && handResults.landmarks && handResults.landmarks.length > 0) {
          // landmarks ë³€í™˜: NormalizedLandmark[][] -> number[][]
          const processedLandmarks: number[][] = handResults.landmarks.flatMap(
            (hand: NormalizedLandmark[]) => hand.map((lm: NormalizedLandmark) => [lm.x, lm.y, lm.z])
          );

          const result: GestureResult = {
            type: "gesture",
            static: { label: "none", confidence: 0 },
            dynamic: { label: "none", confidence: 0 },
            landmarks: processedLandmarks,
            timestamp: timestamp,
          };

          const currentTime = timestamp / 1000; // ì´ˆ ë‹¨ìœ„ ë³€í™˜

          // ê° ì†ì— ëŒ€í•´ ì²˜ë¦¬
          for (let handIndex = 0; handIndex < handResults.landmarks.length; handIndex++) {
            const handLandmarks = handResults.landmarks[handIndex];
            const handKey = `hand_${handIndex}`;

            // ì† ìƒíƒœ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
            if (!this.handStates.has(handKey)) {
              this.initHandState(handKey);
            }

            const handState = this.handStates.get(handKey)!;

            // ì†ëª© ì¢Œí‘œ ì¶”ì¶œ (ëœë“œë§ˆí¬ 0ë²ˆ)
            const wrist = handLandmarks[0];
            const currentWrist2: [number, number] = [wrist.x, wrist.y];
            const currentWrist3: [number, number, number] = [wrist.x, wrist.y, wrist.z];

            // ì›€ì§ì„ ê°ì§€
            let isMoving = false;
            if (handState.prevWrist2 && handState.prevWrist3) {
              const move2d = Math.sqrt(
                Math.pow(currentWrist2[0] - handState.prevWrist2[0], 2) +
                Math.pow(currentWrist2[1] - handState.prevWrist2[1], 2)
              );
              const move3d = Math.sqrt(
                Math.pow(currentWrist3[0] - handState.prevWrist3[0], 2) +
                Math.pow(currentWrist3[1] - handState.prevWrist3[1], 2) +
                Math.pow(currentWrist3[2] - handState.prevWrist3[2], 2)
              );

              handState.moveHist2d.push(move2d);
              if (handState.moveHist2d.length > 8) {
                handState.moveHist2d.shift();
              }

              const avgMove2d = handState.moveHist2d.reduce((a, b) => a + b, 0) / handState.moveHist2d.length;
              // ë™ì  ì œìŠ¤ì²˜ë¥¼ ìœ„í•œ ê· í˜•ì¡íŒ ì›€ì§ì„ ê°ì§€
              const recentMoves = handState.moveHist2d.slice(-2); // ìµœê·¼ 2í”„ë ˆì„
              const hasMovement = recentMoves.some(m => m > this.PX_HIGH * 0.4); // ì ë‹¹í•œ ì„ê³„ê°’
              isMoving = (avgMove2d > this.PX_HIGH * 0.6) || move3d > this.MOVE3D_T * 0.6 || hasMovement;
            }

            // ì •ì  ì œìŠ¤ì²˜ ì²˜ë¦¬
            if (this.aiConfig.gesture.static.enabled && !isMoving) {
              const staticResult = await this.detectStaticGesture(handLandmarks);
              if (staticResult && staticResult.confidence > this.STATIC_CONF_T) {
                // íˆ¬í‘œ ì‹œìŠ¤í…œ
                handState.staticVote.push(staticResult.label);
                if (handState.staticVote.length > this.STATIC_VOTE_K) {
                  handState.staticVote.shift();
                }

                // ë‹¤ìˆ˜ê²° í™•ì¸
                const voteCounts: { [key: string]: number } = {};
                handState.staticVote.forEach(vote => {
                  voteCounts[vote] = (voteCounts[vote] || 0) + 1;
                });

                const maxVotes = Math.max(...Object.values(voteCounts));
                const majorityLabel = Object.keys(voteCounts).find(key => voteCounts[key] === maxVotes);

                if (majorityLabel && majorityLabel !== "none") {
                  if (handState.lastStaticLabel !== majorityLabel) {
                    handState.lastStaticLabel = majorityLabel;
                    handState.staticLabelStart = currentTime;
                  } else if (currentTime - handState.staticLabelStart >= this.STATIC_HOLD_SEC) {
                    // ì¿¨ë‹¤ìš´ ì²´í¬
                    const lastTime = handState.lastStaticTime.get(majorityLabel) || 0;
                    if (currentTime - lastTime >= this.STATIC_COOLDOWN) {
                      result.static = {
                        label: majorityLabel,
                        confidence: staticResult.confidence
                      };
                      handState.lastStaticTime.set(majorityLabel, currentTime);
                    }
                  }
                }
              }
            }

            // ë™ì  ì œìŠ¤ì²˜ ì²˜ë¦¬ - ì‹¤ì œ ì›€ì§ì„ì´ ìˆì„ ë•Œë§Œ ì¸ì‹
            if (this.aiConfig.gesture.dynamic.enabled && isMoving) {
              // ì†ëª© ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œ ê³„ì‚°
              const relativeKeypoints = this.handKeypointsRelative(handLandmarks);
              handState.dynamicSequence.push(relativeKeypoints);

              if (handState.dynamicSequence.length > this.SEQ_LEN) {
                handState.dynamicSequence.shift();
              }

              // ì‹œí€€ìŠ¤ê°€ ì¶©ë¶„íˆ ìŒ“ì˜€ì„ ë•Œ ë™ì  ì œìŠ¤ì²˜ ë¶„ë¥˜
              if (handState.dynamicSequence.length === this.SEQ_LEN) {
                const dynamicResult = await this.detectDynamicGesture(handState.dynamicSequence);
                if (dynamicResult) {
                  // shot ì œìŠ¤ì²˜ëŠ” íŠ¹ë³„íˆ ë†’ì€ ì„ê³„ê°’ ì ìš©
                  const confidenceThreshold = dynamicResult.label === 'shot' ? 0.98 : this.DYN_CONF_T;
                  
                  if (dynamicResult.confidence > confidenceThreshold) {
                    // ì¿¨ë‹¤ìš´ ì²´í¬
                    const lastTime = handState.lastDynTime.get(dynamicResult.label) || 0;
                    if (currentTime - lastTime >= this.DYN_COOLDOWN) {
                      result.dynamic = {
                        label: dynamicResult.label,
                        confidence: dynamicResult.confidence
                      };
                      handState.lastDynTime.set(dynamicResult.label, currentTime);
                      // console.log(`ğŸ¯ ë™ì  ì œìŠ¤ì²˜ ì¸ì‹: ${dynamicResult.label} (${(dynamicResult.confidence * 100).toFixed(1)}%)`);
                    }
                  }
                }
              }
            }

            // ì´ì „ í”„ë ˆì„ ì •ë³´ ì—…ë°ì´íŠ¸
            handState.prevWrist2 = currentWrist2;
            handState.prevWrist3 = currentWrist3;
          }

          // ì†ì´ ê°ì§€ë˜ì—ˆìœ¼ë¯€ë¡œ noHandCount ë¦¬ì…‹
          this.noHandCount = 0;

          return result;
        } else {
          // ì†ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš°
          this.noHandCount++;
          if (this.noHandCount >= this.NOHAND_CLEAR_FR) {
            // ëª¨ë“  ì† ìƒíƒœ ì´ˆê¸°í™”
            this.handStates.clear();
            this.noHandCount = 0;
          }
        }
      } catch (error) {
        // console.debug("GestureProcessor: Hand detection error:", error);
      }
    }
    return null;
  }

  /**
   * ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
   */
  public cleanup(): void {
    // Client-side check
    if (typeof window === 'undefined') {
      return;
    }

    // MediaPipe ëª¨ë¸ë“¤ ì •ë¦¬
    if (this.handLandmarker) {
      try {
        this.handLandmarker.close();
      } catch (error) {
        console.warn("Error closing handLandmarker:", error);
      }
      this.handLandmarker = null;
    }
    if (this.gestureRecognizer) {
      try {
        this.gestureRecognizer.close();
      } catch (error) {
        console.warn("Error closing gestureRecognizer:", error);
      }
      this.gestureRecognizer = null;
    }

    // TensorFlow.js ëª¨ë¸ë“¤ ì •ë¦¬
    if (this.staticGestureModel) {
      try {
        this.staticGestureModel.dispose();
      } catch (error) {
        console.warn("Error disposing static gesture model:", error);
      }
      this.staticGestureModel = null;
    }
    if (this.dynamicGestureModel) {
      try {
        this.dynamicGestureModel.dispose();
      } catch (error) {
        console.warn("Error disposing dynamic gesture model:", error);
      }
      this.dynamicGestureModel = null;
    }

    // ì† ìƒíƒœ ì •ë¦¬
    this.handStates.clear();
    this.noHandCount = 0;

    console.log("GestureProcessor cleaned up.");
  }
}
